apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ include "s3er.fullname" . }}-app-files
  labels:
    {{- include "s3er.labels" . | nindent 4 }}
data:
  entrypoint.sh: |
    pip install boto3
    python -u /app/main.py  # -u Forces the python stdout and stderr streams to be unbuffered, to allow realtime logging from daemon container.

  main.py: |
    import boto3
    import os
    from time import sleep,time

    # configuration
    bucket_name = os.environ["BUCKET_NAME"]
    try:
      sleep_seconds = os.environ["SLEEP_SECONDS_OVERRIDE"]
    except KeyError:
      sleep_seconds = 8

    # define functions
    def ls_bucket(bucket_name):
      response = s3.list_objects(Bucket=bucket_name)
      if "Contents" in response.keys():
        return [object["Key"] for object in response["Contents"]]
      else:
        return []

    def main():
      i = 0
      while True:
        i += 1
        print(f"\n---- iteration {i} ----")
        object_key = f"demofile{i}.txt"
        object_body = f"written at {str(round(time()))}"

        # upload
        print(f"uploading object '{bucket_name}/{object_key}'...")
        print(f"{s3.put_object(Bucket=bucket_name, Key=object_key, Body=object_body)['ResponseMetadata']['HTTPStatusCode']}!")
        print(f"bucket '{bucket_name}' contents: {ls_bucket(bucket_name)}")

        # sleep
        print(f"sleeping for {sleep_seconds} seconds...")
        sleep(sleep_seconds)

        # remove
        print(f"removing object '{bucket_name}/{object_key}'...")
        print(f"{s3.delete_object(Bucket=bucket_name, Key=object_key)['ResponseMetadata']['HTTPStatusCode']}!")
        print(f"bucket '{bucket_name}' contents: {ls_bucket(bucket_name)}")

    if __name__ == "__main__":
      # s3 init
      s3 = boto3.client("s3")

      # verify bucket exists
      s3.head_bucket(Bucket=bucket_name)["ResponseMetadata"]["HTTPStatusCode"]

      # trigger main loop
      main()
